@inproceedings{zhong-litman-2025-tale,
  title     = {A Tale of Evaluating Factual Consistency: Case Study on Long Document Summarization Evaluation},
  author    = {Zhong, Yang  and
               Litman, Diane},
  editor    = {Che, Wanxiang  and
               Nabende, Joyce  and
               Shutova, Ekaterina  and
               Pilehvar, Mohammad Taher},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2025},
  month     = jul,
  year      = {2025},
  address   = {Vienna, Austria},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.findings-acl.648/},
  doi       = {10.18653/v1/2025.findings-acl.648},
  pages     = {12511--12532},
  isbn      = {979-8-89176-256-5},
  abstract  = {Ensuring factual consistency in summarization remains a challenge, especially for long-document evaluation. While automated, reference-free evaluation models are essential given the impracticality of large-scale human assessment for lengthy texts, challenges persist in evaluating different systems on how to handle different summary granularities and evolving model generations. In this work, we conduct a systematic study on diverse factual-consistency evaluation systems across four long-document datasets, encompassing summaries generated by models from non-LLMs to proprietary LLMs. Our analysis reveals that fine-grained continuous scores can provide more reliable assessments of different evaluation systems' capabilities than binary classification. We also examine the relationship between sentence-level and summary-level model performance, highlighting its dependency on dataset characteristics. Moreover, our study reveals that advanced systems can achieve higher recall in error detection for older summaries, yet struggle with false positives and fine-grained error detection. Our analysis and case studies provide further insights into designing robust factuality evaluation systems, which are becoming increasingly in demand as generative models advance rapidly.}
}